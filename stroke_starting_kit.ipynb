{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>\n",
    "    <img src=\"https://raw.githubusercontent.com/ramp-kits/stroke/master/figs/logo_inria.png\" width=\"150px\"/><img src=\"https://raw.githubusercontent.com/ramp-kits/stroke/master/figs/logo_cds.png\" width=\"150px\" />\n",
    "</center>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src=\"https://raw.githubusercontent.com/ramp-kits/stroke/master/figs/stroke_logo.png\" width=\"400px\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> RAMP: segmentation of the brain lesions </center>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: left\">\n",
    "    <em>\n",
    "        <i><b>Authors: </b>Maria Tele≈Ñczuk, Swetha Shanker, Guillaume Lemaitre, Alexandre Gramfort</i>\n",
    "        <a href=\"http://www.datascience-paris-saclay.fr\">Paris-Saclay Center for Data Science</a> (Inria), France<br>\n",
    "    </em>\n",
    "    <em>  \n",
    "        <i>Sook-Lei Liew</i>\n",
    "        <a href=\"https://chan.usc.edu/npnl/\">Neural Plasticity & Neurorehabilitation Lab</a> (USC), USA<br>\n",
    "        </em>\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#Introduction)\n",
    "3. [Submission](#Submission) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clinical/research motivation\n",
    "\n",
    "Stroke is the leading cause of adult disability worldwide, with up to two-thirds of individuals experiencing long-term disabilities. Large-scale neuroimaging studies have shown promise in identifying robust biomarkers (e.g., measures of brain structure) of long-term stroke recovery following rehabilitation. However, analyzing large rehabilitation-related datasets is problematic due to barriers in accurate stroke lesion segmentation. Manually-traced lesions are currently the gold standard for lesion segmentation on T1-weighted MRIs, but are labor-intensive, time consuming, and require anatomical expertise and training. Manual segmentation can also be subjective. While algorithms have been developed to automate this process, the resulting lesion masks often lack the accuracy needed to make them viable solutions. However, newer algorithms that employ machine-learning and deep learning techniques are promising avenues, but they require large, diverse datasets for training and testing and developing generalizable models. In this challenge, training can be performed on our public ATLAS 2.0 dataset, and testing is done with a hidden private dataset comprised of multi-site data from the same sites as ATLAS 2.0. <BR>\n",
    "\n",
    "For more information rever to:\n",
    "<a href=\"http://fcon_1000.projects.nitrc.org/indi/retro/atlas.html\">Anatomical Tracings of Lesions After Stroke</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1361841516301268\">1. Maier, Oskar, et al. \"ISLES 2015-A public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI.\" Medical image analysis 35 (2017): 250-269.</a><br>\n",
    "\n",
    "<a href=\"https://www.nature.com/articles/sdata201811\">2. Liew, Sook-Lei, et al. \"A large, open source dataset of stroke anatomical brain images and manual lesion segmentations.\" Scientific data 5 (2018): 180011.</a><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective of the challenge\n",
    "\n",
    "In this challenge you will be given 3D medical images (T1 MRI scans in `nii.gz` format) of the stroke patients and the files with the corresponding lesions (binary masks) traced by hand by experts. Your algorithm will be scored on the precision. Before we look closer at the data, let's import all the necessary libraries (feel free to skip it if you have done it already):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python >= 3.7\n",
    "- [nilearn](https://nilearn.github.io/)\n",
    "- [numpy](https://pypi.org/project/numpy/)\n",
    "- [osfclient](https://github.com/osfclient/osfclient)  # used for downloading the data\n",
    "- [scipy](https://pypi.org/project/scipy/)\n",
    "- [pandas](https://pypi.org/project/pandas/)\n",
    "- [scikit-learn](https://pypi.org/project/scikit-learn/)\n",
    "- [matplolib](https://pypi.org/project/matplotlib/)\n",
    "- [jupyter](https://pypi.org/project/jupyter/)\n",
    "- [ramp-workflow](https://pypi.org/project/ramp-workflow/)\n",
    "- [ramp-utils](https://github.com/paris-saclay-cds/ramp-board/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will install the required pacakge dependencies, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/maja/anaconda3/lib/python3.7/site-packages (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.18.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: scikit-image in /home/maja/anaconda3/lib/python3.7/site-packages (0.15.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-image) (6.2.0)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-image) (2.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-image) (1.0.3)\n",
      "Requirement already satisfied: imageio>=2.0.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-image) (2.6.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from networkx>=2.0->scikit-image) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/maja/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/maja/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.18.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/maja/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /home/maja/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (41.4.0)\n",
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/44/e1/dc0757b20b56c980b5553c1b5c4c32d378c7055ab7bfa92006801ad359ab/Keras-2.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from keras) (1.18.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/maja/anaconda3/lib/python3.7/site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: pyyaml in /home/maja/anaconda3/lib/python3.7/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: h5py in /home/maja/anaconda3/lib/python3.7/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: six in /home/maja/anaconda3/lib/python3.7/site-packages (from h5py->keras) (1.12.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Requirement already satisfied: ramp-workflow in /home/maja/anaconda3/lib/python3.7/site-packages (0.4.0.dev0)\n",
      "Requirement already satisfied: pandas in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.1.2)\n",
      "Requirement already satisfied: joblib in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (0.13.2)\n",
      "Requirement already satisfied: cloudpickle in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (0.23.2)\n",
      "Requirement already satisfied: click in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (7.0)\n",
      "Requirement already satisfied: scipy in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.3.1)\n",
      "Requirement already satisfied: numpy in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.18.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-workflow) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-workflow) (2019.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.22->ramp-workflow) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/maja/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->ramp-workflow) (1.12.0)\n",
      "Requirement already satisfied: ramp-utils in /home/maja/anaconda3/lib/python3.7/site-packages (0.6.1)\n",
      "Requirement already satisfied: pyyaml in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-utils) (5.1.2)\n",
      "Requirement already satisfied: pandas in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-utils) (1.1.2)\n",
      "Requirement already satisfied: click in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-utils) (7.0)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-utils) (1.18.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-utils) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-utils) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/maja/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->ramp-utils) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install scikit-image\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install ramp-workflow\n",
    "!{sys.executable} -m pip install ramp-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get this notebook running and test your models locally using `ramp-test` (from ramp-workflow), we recommend that you use the Anaconda or Miniconda Python distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data has not yet been downloaded locally, uncomment the following cell and run it. You need to have enough space to story it locally.\n",
    "\n",
    "<font color='red'>Note: Please be patient, the data is large (~3 GB). </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python download_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to find the test and train folders in the data/ directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your `data` folder you should now be able to find the `test` and `train` directories, each with a number of the files named: `1_T1.nii.gz` and `1_lesion.nii.gz`, `2_T1.nii.gz` and `2_lesion.nii.gz` and so on\n",
    " - `x_T1.nii.gz` is a file with a 3D T1 (MRI) brain scan of the patient\n",
    " - `x_lesion.nii.gz` is a file with the binary mask of the same size as T1 image. 0 corresponds to no lesion, 1 corresponds to the lesion. The true lesions where traced by the experts by hand\n",
    "\n",
    "If you wish to view any of those files from outside of Python, there are many applications available online. For example you might want to use [ITK-snap](http://www.itksnap.org/pmwiki/pmwiki.php). There, you can load the `T1.nii.gz` as a Main Image and `lesion.nii.gz` as a Segmentation to overlap the two. Here, we won't go into the details of how to use ITK-snap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the images to Python, we will be using [Nilearn](https://nilearn.github.io/) Python library, but there are other possible options so feel free to choose your favorite one (if, for your submission, you will want to use a libarary which is not listed within the `requirements.txt` or `extra_libraries.txt` files please make a pull request to the the [Stroke Lesion Segmentation Challenge repository on github](https://github.com/ramp-kits/stroke) by adding the required library to [extra_libraries.txt](https://github.com/ramp-kits/stroke/blob/master/extra_libraries.txt) file)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MRI](https://en.wikipedia.org/wiki/Magnetic_resonance_imaging#:~:text=Magnetic%20resonance%20imaging%20(MRI)%20is,the%20organs%20in%20the%20body.) is short for the Magnetic Resonance Imaging. MRI images consist of scans of the brain at different depths and then combined together to form the 3d image of the brain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view few of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_T1_1 = 'data/train/1_T1.nii.gz'\n",
    "path_T1_2 = 'data/train/2_T1.nii.gz'\n",
    "path_T1_3 = 'data/train/4_T1.nii.gz'\n",
    "\n",
    "path_lesion_1 = 'data/train/1_lesion.nii.gz'\n",
    "path_lesion_2 = 'data/train/2_lesion.nii.gz'\n",
    "path_lesion_3 = 'data/train/4_lesion.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nilearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2ca25d3c7af6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnilearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nilearn'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from nilearn import plotting\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def plot_t1(path_to_t1, title='T1'):\n",
    "    fig = plt.figure(1, figsize=(14, 5), frameon=False, dpi=50)\n",
    "    ax = plt.gca()\n",
    "    plotting.plot_anat(path_to_t1, title=title,\n",
    "                       axes=ax,\n",
    "                       draw_cross=False,\n",
    "                       annotate=False,\n",
    "                       cut_coords=(0, 0, 0)\n",
    "                       )\n",
    "plot_t1(path_to_t1=path_T1_1, title=f'{path_T1_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO: choose the images with 1) no visible lesion; 2) small lesion; 3) large lesion </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_t1(path_to_t1=path_T1_2, title=f'{path_T1_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_t1(path_to_t1=path_T1_3, title=f'{path_T1_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the T1 image for three different patients shown at three different axes. Some preprocessing has been done to them already. If you are interested, you can check the preprocessing steps in [here](https://www.nature.com/articles/sdata201811)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you already make some guesses on where the lesions are located?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look closer at the lesions, let's look at the size of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import load_img\n",
    "from joblib import Memory\n",
    "\n",
    "mem = Memory('.')\n",
    "\n",
    "@mem.cache\n",
    "def load_img_data(fname):\n",
    "    return load_img(fname).get_fdata()\n",
    "\n",
    "img1 = load_img_data(path_T1_1)\n",
    "img2 = load_img_data(path_T1_2)\n",
    "img3 = load_img_data(path_T1_3)\n",
    "\n",
    "print(f\"Shape of the first T1 scan is: {img1.shape}, \"\n",
    "      \"of the second: {img2.shape}, of the third: {img3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we checked the sizes of only three of the scans, but if you look at the others you will notice that they all have the same size. This is because one of our preprocessing steps was to normalize all of the data to MNI space. \n",
    "\n",
    "Now, look closer at the images which we plotted above: even though the brains were normalized into the common space you can easily notice differences between them. \n",
    "\n",
    "By normalizing to the MNI space we are trying to align and warp the brain to match the template brain. This also leads to normalization of the size of the image, hece the same shape of all the scans we have here.\n",
    "\n",
    "If you find it useful you can use the MNI brain which we used in the preprocessing. You can find it here:\n",
    "<font color='red'>TODO: add link to the MNI brain used (Lei?) </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesion analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we understand better the anatomical T1 images that we will work with, let's look at the lesion masks. We will visualize overlap of the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_overlap(path_to_t1, path_to_lesion, title='overlap'):\n",
    "    fig = plt.figure(1, figsize=(14, 5), frameon=False, dpi=50)\n",
    "    ax = plt.gca()\n",
    "    plotting.plot_roi(path_to_lesion, path_to_t1, title=title,\n",
    "                       axes=ax,\n",
    "                       draw_cross=False,\n",
    "                       annotate=False, \n",
    "                       cmap='autumn',  # the lesions will be shown in red\n",
    "                       cut_coords=(0, 0, 0)\n",
    "                       )\n",
    "plot_overlap(path_to_t1=path_T1_1,\n",
    "             path_to_lesion=path_lesion_1,\n",
    "             title=f'overlap, {path_T1_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlap(path_to_t1=path_T1_2,\n",
    "             path_to_lesion=path_lesion_2,\n",
    "             title=f'overlap, {path_T1_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overlap(path_to_t1=path_T1_3,\n",
    "             path_to_lesion=path_lesion_3,\n",
    "             title=f'overlap, {path_T1_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you guess correctly the locations of the lesions? What else did you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably the most noticable thing is that the lesions are not of the same size nor they are in the same location. In one of the subjects, the lesion is not even in the plane that we are looking at, or is it there at all?\n",
    "\n",
    "Feel free to also look at the data of other subjects. You can view different planes by changing `cut_coords` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now look at the voxel sizes of the lesions of some patients (here we will consider only 100 of them). First we will find all the paths to the truth and lesions in our `train` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "t1_name = '*T1.nii.gz'\n",
    "lesion_name = '_lesion.nii.gz'\n",
    "\n",
    "# list_subj_dirs_train = os.listdir(dir_data_train)\n",
    "def find_data_pairs(data_dir, data_type='.nii.gz'):\n",
    "    t1_names = glob.glob(os.path.join(data_dir, t1_name))\n",
    "    X_path = []\n",
    "    y_path = []\n",
    "    for t1_next in t1_names:\n",
    "        X_path.append(t1_next)\n",
    "        y_path.append(t1_next[:-(len(t1_name))]+lesion_name)\n",
    "    return X_path, y_path\n",
    "\n",
    "data_dir = 'data/train'  # path to your data directory\n",
    "#data_dirs = os.listdir(data_dir)\n",
    "Xpatsh, ypaths = find_data_pairs(data_dir, data_type='.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_sizes = np.empty(len(ypaths))\n",
    "for idx, lesion_path in enumerate(ypaths):\n",
    "    truth = load_img(lesion_path)\n",
    "    truth_data = truth.get_fdata()\n",
    "    truth_size = int(np.sum(truth_data))\n",
    "    lesion_sizes[idx] = truth_size\n",
    "    del truth, truth_data\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(np.log10(lesion_sizes), bins=10, color='red')\n",
    "ax.set_xlabel('$\\log_{10}$(lesion size in voxels)')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "print('There are: ', len(ypaths),\n",
    "      ' lesion files, with smallest lesion: ', np.min(lesion_sizes),\n",
    "      ' and largest: ', np.max(lesion_sizes), ' of voxels.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: just food for thought (must faster to laod numpy array), remove before pudice_coeffblicshing\n",
    "# the starting kit:\n",
    "%timeit load_img(path_T1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_file = load_img(path_T1_3).get_fdata()\n",
    "np.savez('temp_t1.npz', t1_file)\n",
    "%timeit t2_file = np.load('temp_t1.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>TODO: Make sure there are no lesions of size 0 in the actual data. Adjust the above plot once the correct data is available  </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the lesions vary a lot between patients.\n",
    "\n",
    "<font color='red'>Note: All the images include at least a small lesion. </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample prediction algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get familiar with the way we expect you to submit your algorithm we will now go through some sample/ dummy solutions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy solution (predict only 1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the path of this challenge you can find a directory called `submissions/sample`. If you want to test your solution locally you will need to place your submission directory in the `submissions` folder, eg `submissions/my_submission`. There, you will need to have a python file called `estimator.py`. Let's look at the `submissions/sample/estimator.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/sample/estimator.py\n",
    "from nilearn.image import load_img\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "class Dummy(BaseEstimator, ClassifierMixin, TransformerMixin):\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # returns y filled with only 1s\n",
    "\n",
    "        x_path = X[0]\n",
    "        x_data = load_img(x_path)\n",
    "        x_shape = x_data.shape\n",
    "        y = np.ones((len(X), x_shape[0], x_shape[1], x_shape[2]))\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "def get_estimator():\n",
    "\n",
    "    # sets all the masks to all 1s\n",
    "    dummy = Dummy()\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', dummy)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test this or any other submission with the command (in your terminal):\n",
    "\n",
    "`ramp-test --submission <your submission folder name> --quick-test`\n",
    "\n",
    "`--quick-test` tells RAMP to use only 5 subjects from the dataset. Omit this option if you wish to train on the whole dataset (this will take more time)\n",
    "\n",
    "RAMP will be searching for the function `get_estimator()` within your `estimator.py` file. This function needs to return [Sklearn type of pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).\n",
    "\n",
    "So how does it work?\n",
    "\n",
    "RAMP will use functions `get_train_data()` and `get_test_data()` which are found in the `problem.py` file in current challenge directory (you are free to view this file, but you will not be able to submit other version of it). Those functions will return `X` and `y` data. \n",
    "\n",
    "`X` is an array which stores the paths to the `T1.nii.gz` (we are not loading them all to the memory as you might find it more efficient to work with each of them separately or with small batches of data). In our Dummy algorithm above we are loading the data using `load_img()` function from `nilearn.image`. \n",
    "\n",
    "\n",
    "`y` is an array with four dimensions: `n_samples` x `x_len` x `y_len` x `z_len` where `x_len`, `y_len` and `z_len` are dimensions of the MRI scans. In the Dummy algorithm we are not using `y` for trainining (ie in `fit()`), however test `y` data is compared to your solution and used to score the output.\n",
    "\n",
    "Let's go step by step through what happens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train dataset (we will load only data for 5 subjects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(xy_paths, n_samples=None):\n",
    "    xs, ys = xy_paths\n",
    "    # use only n_samples subjects here\n",
    "    if n_samples:\n",
    "        n_samples = min(len(xs), n_samples)\n",
    "    else:\n",
    "        n_samples = min(len(xs))\n",
    "    X = xs[:n_samples]\n",
    "    y = ys[:n_samples]\n",
    "    return X, y\n",
    "\n",
    "dir_data_train = 'data/train'\n",
    "list_subj_dirs_train = find_data_pairs(dir_data_train)\n",
    "\n",
    "X_train, y_train = get_data(list_subj_dirs_train, n_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain potential possiblity to use AWS services/ limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_train is a {type(X_train)} with {len(X_train)} elements: \\n{X_train}\\n')\n",
    "print(f'y_train is a {type(y_train)} with {len(y_train)} elements: \\n{y_train}\\n.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although, RAMP will use cross validation to train and test your data we will not showcase it here. However note, that when testing your algorithm locally you will see a score for each of your cross validation steps and the combined score in the end.\n",
    "\n",
    "Here we will directly fit the algorithm of all our loaded train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_pipe = get_estimator()\n",
    "dummy_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load the test dataset. Here, we will limit it to 3 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data_test = 'data/test'\n",
    "list_subj_dirs_test = find_data_pairs(dir_data_test)\n",
    "\n",
    "X_test, y_test = get_data(list_subj_dirs_test, n_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'X_test is a {type(X_test)} with {len(X_test)} elements: \\n{X_test}\\n')\n",
    "print(f'y_test is a {type(y_test)} with {len(y_test)} elements: \\n{y_test}\\n')\n",
    "print(f'Its unique elements include {np.unique(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get predicted `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dummy_pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'y_pred is a {type(y_pred)} of shape: {y_pred.shape}.')\n",
    "print(f'Its unique elements include {np.unique(y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is what we expected. `y_pred` is of the same shape as `y_test` and it includes only 1s.\n",
    "\n",
    "What RAMP is doing next is scoring the predictions. The score which RAMP is using for this challenge is defined in the `problem.py` file: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scores used\n",
    "- <b>Dice‚Äôs coefficient (DC)</b>: describes the volume overlap between two segmentations and is sensitive to the lesion size; read more in [Wikipedia](https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient). It ranges between 0 and 1 with 1 being a maximum score.\n",
    "- <b>Precision</b>: the ability not to label as truth location which is not true; read more in [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html). It ranges between 0 and 1 with 1 being a maximum score.\n",
    "- <b>Recall</b>: measures true positive rate; read more in [Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html?highlight=recall#sklearn.metrics.recall_score). It ranges between 0 and 1 with 1 being a maximum score.\n",
    "- <b>Hausdorff Distance</b>: a measure of the maximum surface distance, hence especially sensitive to outliers maximum of all surface distances; read more in [Wikipedia](https://en.wikipedia.org/wiki/Hausdorff_distance). It ranges between 0 and inifinty with 0 being a best score.\n",
    "<font color='red'>TODO: are we going to use Hausdorff? really slow!  </font> \n",
    "- <b>Absolute Volume Difference (AVD)</b>: It ranges between 0 and 1 with 0 being a best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import DiceCoeff, Precision, Recall\n",
    "from problem import HausdorffDistance, AbsoluteVolumeDifference\n",
    "\n",
    "dice_coeff = DiceCoeff()\n",
    "precision = Precision()\n",
    "recall = Recall()\n",
    "# hausdorff = HausdorffDistance()  # takes very long time\n",
    "avd = AbsoluteVolumeDifference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_dummy = dice_coeff(y_test, y_pred)\n",
    "#print(f'DiceCoeff for Dummy algorithm is {np.round(dice_dummy, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_dummy = precision(y_test, y_pred, valid_indices=None)\n",
    "print(f'Precision for Dummy algorithm is {np.round(precision_dummy, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_dummy = recall(y_test, y_pred, valid_indices=None)\n",
    "print(f'Recall for Dummy algorithm is {np.round(recall_dummy, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avd_dummy = avd(y_test, y_pred, valid_indices=None)\n",
    "print(f'AbsoluteVolumeDifference for Dummy algorithm is {np.round(avd_dummy, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the score which you should get when testing locally using\n",
    "\n",
    "`ramp-test --submission <your submission folder name> --quick-test`\n",
    "\n",
    "If you submit the Dummy solution on RAMP the score might vary slightly because for testing your algorithm RAMP will use different dataset, precisely:\n",
    "\n",
    "`ramp-test --submission sample --quick-test`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A (slightly) more complex algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the today's world when one think of image segmentation they instantly associate it with deep learning algorithms. We do support deep learning solutions. Each of the algorithms submitted to this challenge will be trained on the AWS instances with access to a GPU.\n",
    "\n",
    "<font color='red'>Note that there is a limit allocated to each participant:</font>\n",
    "<font color='red'>\n",
    "\n",
    "<font color='red'>1. TODO: add max number of submissions</font>\n",
    "    \n",
    "<font color='red'>2. TODO: hours of GPU time per submission allocated to each participant</font>\n",
    "    \n",
    "<font color='red'>3. TODO: frequency of allowed submissions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we will first try more classical machine learning solution. We will consider different features of each of the pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably realized that we are using a lot of pixels which we do not even want to classify: those outside of the brain. Now we will draw all the 0s in the anatomical image in green and all the others in gray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "cmap_nobrain = colors.ListedColormap(['green','gray'])\n",
    "\n",
    "img1[np.abs(img1) > 0] = 1\n",
    "plt.imshow(img1[:, :, 100], cmap=cmap_nobrain,\n",
    "           interpolation='none',\n",
    "           alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems reasonable to completely ignore all the voxels which in the anatomical T1 scan are 0.\n",
    "\n",
    "We will use functions from [Scikit-Learn](https://scikit-learn.org/stable/) and [Scikit-Image](https://scikit-image.org/) Python libraries.\n",
    "This solution is partly reused from [here](https://eoss-image-processing.github.io/2020/06/24/trainable-segmentation.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/estimator.py\n",
    "from nilearn.image import load_img\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from skimage import filters\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def _get_average(self, X):\n",
    "        for idx, x_path in enumerate(X):\n",
    "            x_data = load_img(x_path).get_fdata()\n",
    "\n",
    "            if idx == 0:\n",
    "                x_avg = x_data\n",
    "            else:\n",
    "                x_avg += x_data\n",
    "        x_avg = x_avg / (idx + 1)  # make average\n",
    "        return x_avg\n",
    "\n",
    "    def _singlescale_basic_features(self, X, sigma, intensity=True,\n",
    "                                    edges=True,\n",
    "                                    avg_subtract=True):\n",
    "        \"\"\" Features for a single value of the Gaussian blurring parameter\n",
    "            ``sigma``\n",
    "            simplified from version written by:\n",
    "                Nicholas Esterer and Emmanuelle Gouillart\n",
    "        \"\"\"\n",
    "        for idx, x_path in enumerate(X):\n",
    "            features = []\n",
    "            img = load_img(x_path).get_fdata()\n",
    "            img_blur = filters.gaussian(img, sigma)\n",
    "\n",
    "            # intensity:\n",
    "            img_blur_reshaped = img_blur.reshape((1, -1))\n",
    "            features.append(img_blur_reshaped)\n",
    "\n",
    "            # edges:\n",
    "            features.append(filters.sobel(img_blur).reshape(1, -1))\n",
    "\n",
    "            # average subtract\n",
    "            features.append((img - self._x_avg).reshape(1, -1))\n",
    "            # as the last feature add the average brain\n",
    "            # this will be used to remove all 0s (supposedly what's around\n",
    "            # the brain)\n",
    "            features.append(self._x_avg.reshape(1, -1))\n",
    "            features = np.array(features)\n",
    "            features = features.reshape((4, -1))\n",
    "\n",
    "            # average brain\n",
    "            if not idx:\n",
    "                features_x = features\n",
    "            else:\n",
    "                features_x = np.hstack([features_x, features])\n",
    "        return features_x\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self._x_avg = self._get_average(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = self._singlescale_basic_features(X=X, sigma=0.2)\n",
    "        return features\n",
    "\n",
    "\n",
    "class PointEstimator(BaseEstimator):\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        _nonzero_indices = X[-1] != 0\n",
    "\n",
    "        y_loaded = np.empty([1, X.shape[1]])\n",
    "        for i in range(len(y)):\n",
    "            y_temp = load_img(y[i]).get_fdata()\n",
    "            self.img_shape = y_temp.shape\n",
    "            y_temp = y_temp.reshape((1, -1))\n",
    "            y_loaded[:, i*y_temp.shape[1]:(i+1)*y_temp.shape[1]] = y_temp\n",
    "\n",
    "        # remove the last, average feature\n",
    "        _X_no_zeros = X[:-1, _nonzero_indices]\n",
    "        _y_no_zeros = y_loaded[:, _nonzero_indices]\n",
    "        self.clf = LogisticRegression(class_weight=\"balanced\")\n",
    "        self.clf.fit(_X_no_zeros.T, _y_no_zeros.ravel())\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # remove 0s from average train data (4th feature)\n",
    "        _nonzero_indices = X[-1] != 0\n",
    "        _X_no_zeros = X[:-1, _nonzero_indices]\n",
    "\n",
    "        _y_pred_no_zeros = self.clf.predict(_X_no_zeros.T)\n",
    "        y_pred = np.zeros(len(X[0]))\n",
    "        y_pred[_nonzero_indices] = _y_pred_no_zeros\n",
    "        y = y_pred.reshape(-1, self.img_shape[0],\n",
    "                           self.img_shape[1],\n",
    "                           self.img_shape[2])\n",
    "        return y\n",
    "\n",
    "\n",
    "def get_estimator():\n",
    "\n",
    "    extractor = FeatureExtractor()\n",
    "    point_estimator = PointEstimator()\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('extractor', extractor),\n",
    "        ('estimator', point_estimator)\n",
    "    ])\n",
    "\n",
    "    return pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are calculating different features found in the data:\n",
    "\n",
    "1. color intensity of the pixels\n",
    "2. edges\n",
    "3. image subtracted by total average of the train data\n",
    "\n",
    "Next we pass those features to the point estimator which uses it to fit two clusters using [KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) algorithm.\n",
    "\n",
    "Let's run it with our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipe = get_estimator()\n",
    "features_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_features = features_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now plot the true and predicted lesions over the brain image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "def plot_overlap_true_pred(ax, brain_img, true_mask, predicted_mask, title='overlap'):\n",
    "    cmap_true = colors.ListedColormap(['white', 'red'])\n",
    "    cmap_pred = colors.ListedColormap(['white','blue'])\n",
    "    if np.all(predicted_mask == 1):\n",
    "        cmap_pred = cmap_pred.reversed()\n",
    "    ax.imshow(brain_img, cmap='Greys')\n",
    "    ax.imshow(predicted_mask, cmap=cmap_pred,\n",
    "               interpolation='none',\n",
    "               alpha=0.5)\n",
    "    ax.imshow(true_mask, cmap=cmap_true,\n",
    "               interpolation='none',\n",
    "               alpha=0.5)\n",
    "    \n",
    "    patches = []\n",
    "    patches.append(Patch(color='red', label=\"truth\"))\n",
    "    patches.append(Patch(color='blue', label=\"predict\"))\n",
    "    ax.legend(handles=patches, bbox_to_anchor=(1.05, 1), loc=1, borderaxespad=0. )\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.set_title(title)\n",
    "\n",
    "    \n",
    "def load_images_and_plot(X_test, y_test, y_pred):\n",
    "    f, axes = plt.subplots(1, len(X_test), figsize=(14, 8))\n",
    "    z_axis_cut = 100\n",
    "    for idx, brain_img_path in enumerate(X_test):\n",
    "        # plot the test case\n",
    "        brain_img = load_img(brain_img_path).get_fdata()\n",
    "        lesion_mask = load_img(y_test[idx]).get_fdata()\n",
    "        pred_lesion_mask = y_pred[idx]\n",
    "        plot_overlap_true_pred(\n",
    "            ax = axes[idx],\n",
    "            brain_img=brain_img[:, :, z_axis_cut],\n",
    "            predicted_mask=pred_lesion_mask[:,:,z_axis_cut],\n",
    "            true_mask=lesion_mask[:, :, z_axis_cut],\n",
    "            title=f'{brain_img_path}')\n",
    "\n",
    "        # print the size of the true and the predicted lesion\n",
    "        print('Size of Truth is ',\n",
    "              np.sum(lesion_mask[idx]),\n",
    "              ' vs ',\n",
    "              np.sum(pred_lesion_mask[idx]),\n",
    "              ' of Predict. For ',\n",
    "              brain_img_path)\n",
    "\n",
    "load_images_and_plot(X_test, y_test, y_pred_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer to view it at another dimension you can change `z_axis_cut` parameter or define your own cut at `x` or `y` axis.\n",
    "\n",
    "This is not an amazing result. Our model seems to be predicting some forms on the brain rather than the lesion. Still, let's calculate the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_fext = dice_coeff(y_test, y_pred)\n",
    "print(f'DiceCoeff for Feature Extractor algorithm is {np.round(dice_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_fext  = precision(y_test, y_pred, valid_indices=None)\n",
    "print(f'Precision for Feature Extractor algorithm is {np.round(precision_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fext  = recall(y_test, y_pred)\n",
    "print(f'Recall for Feature Extractor algorithm is {np.round(recall_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avd_fext  = avd(y_test, y_pred)\n",
    "print(f'AbsoluteVolumeDifference for Feature Extractor algorithm is {np.round(avd_fext, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to the 3D image segmentation deep learning algorithms are a frequent choice of consideration. Be careful not to be tricked into thinking that it might be the only working solution.\n",
    "\n",
    "We prepared for you three sample deep learning solutions for you. We will explain it here, but we won't be running it from this notebook. Feel free to use it and reuse it for your own solutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %file submissions/deep_learn/estimator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the generator pattern (an iterable)\n",
    "class ImageLoader():\n",
    "\n",
    "    def __init__(self, X_paths, y=None):\n",
    "        self.X_paths = X_paths\n",
    "        self.n_paths = len(X_paths)\n",
    "        self.y = y\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "\n",
    "    def load(self, img_index):\n",
    "        img = load_img(self.X_paths[img_index]).get_fdata()\n",
    "        print(img_index)\n",
    "        if self.y is not None:\n",
    "            return img, self.y[img_index]\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with fit (in the starting kit example, we load some pretrained weights to be able to show results here, but note this is not possible for an actual submission):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_pipe = get_estimator()\n",
    "deep_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_deep = deep_pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_deep)\n",
    "print(y_pred_deep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_images_and_plot(X_test, y_test, y_pred_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred_deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(y_pred_deep[0] == y_pred_deep[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    predict few of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "show the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_fext = dice_coeff(y_test, y_pred)\n",
    "print(f'DiceCoeff for Feature Extractor algorithm is {np.round(dice_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_fext  = precision(y_test, y_pred, valid_indices=None)\n",
    "print(f'Precision for Feature Extractor algorithm is {np.round(precision_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_fext  = recall(y_test, y_pred)\n",
    "print(f'Recall for Feature Extractor algorithm is {np.round(recall_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avd_fext  = avd(y_test, y_pred)\n",
    "print(f'AbsoluteVolumeDifference for Feature Extractor algorithm is {np.round(avd_fext, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the reference, if you wish to view previous medical image segmentation challenges:\n",
    "    \n",
    "- [Cada (Cerebral Aneurysm Detection) grand-challenge](https://cada.grand-challenge.org/)\n",
    "- [Augmented Segmentation of Coronary Arteries](https://asoca.grand-challenge.org/)\n",
    "- [TN (Thyroid Nodule Segmentation and Classification) SCUI2020](https://tn-scui2020.grand-challenge.org/)\n",
    "- [Pneumothorax Segmentation SIIM-ACR](https://www.kaggle.com/c/siim-acr-pneumothorax-segmentation)\n",
    "- [Brats brain tumor segmentation Challenge 2020](https://www.med.upenn.edu/cbica/brats2020/data.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission <a class=\"anchor\" id=\"Submission\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you found a good model you wish to test you should place it in a directory, naming it as you wish, and place it in the `submissions/` folder (you can already find there two submissions in the folders `submissions/starting_kit` and `submissions/sample` which we talked about above). The file placed in your submission directory (e.g., `starting_kit/` should be called `estimator.py` and should define a function called `get_estimator` that returns a scikit-learn type of pipeline.\n",
    "\n",
    "You can then test your submission locally using the command:\n",
    "\n",
    "`ramp-test --submission <your submission folder name>`\n",
    "\n",
    "if you prefer to run a quick test on much smaller subset of data you can add `--quick-test` option:\n",
    "\n",
    "`ramp-test --submission <your submission folder name> --quick-test`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on how to submit your code on [ramp.studio](https://ramp.studio/), refer to the [online documentation](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/stable/using_kits.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
