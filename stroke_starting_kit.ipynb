{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center\">\n",
    "<img src=\"figs/stroke_logo.png\" width=\"350px\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAMP: segmentation of the brain lesions\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: left\">\n",
    "    <em>\n",
    "        <i>Authors: Maria Tele≈Ñczuk, Swetha Shankar, Lucy Liu, Guillaume Lemaitre, Alexandre Gramfort</i>\n",
    "        <a href=\"http://www.datascience-paris-saclay.fr\">Paris-Saclay Center for Data Science</a> (Inria), France<br>\n",
    "    </em>\n",
    "    <em>  \n",
    "        <i>Sook-Lei Liew</i>\n",
    "        <a href=\"https://chan.usc.edu/npnl/\">Neural Plasticity & Neurorehabilitation Lab</a> (USC), USA<br>\n",
    "        </em>\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Introduction](#Introduction)\n",
    "3. [Submission](#Submission) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a class=\"anchor\" id=\"Introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stroke is the leading cause of adult disability worldwide, with up to two-thirds of individuals experiencing long-term disabilities. Large-scale neuroimaging studies have shown promise in identifying robust biomarkers (e.g., measures of brain structure) of stroke recovery. However, analyzing large datasets is problematic due to barriers in accurate stroke lesion segmentation. Manually-traced lesions are currently the gold standard for lesion segmentation, but are labor intensive and require anatomical expertise. While algorithms have been developed to automate this process, the results often lack accuracy. Newer algorithms that employ machine-learning techniques are promising, yet these require large training datasets to optimize performance.<br>\n",
    "\n",
    "More information:\n",
    "<a href=\"http://fcon_1000.projects.nitrc.org/indi/retro/atlas.html\">Anatomical Tracings of Lesions After Stroke</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.sciencedirect.com/science/article/abs/pii/S1361841516301268\">1. Maier, Oskar, et al. \"ISLES 2015-A public evaluation benchmark for ischemic stroke lesion segmentation from multispectral MRI.\" Medical image analysis 35 (2017): 250-269.</a><br>\n",
    "\n",
    "<a href=\"https://www.nature.com/articles/sdata201811\">2. Liew, Sook-Lei, et al. \"A large, open source dataset of stroke anatomical brain images and manual lesion segmentations.\" Scientific data 5 (2018): 180011.</a><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this challenge you will be given 3D medical images (T1 MRI scans) of the stroke patients and the files with the corresponding lesions (binary masks) traced by hand by experts. Your algorithm will be scored on the timing and the precision. Before we look closer at the data, let's import all the necessary libraries (unless you have done it already):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Python >= 3.7\n",
    "- [nilearn](https://nilearn.github.io/)\n",
    "- [numpy](https://pypi.org/project/numpy/)\n",
    "- [scipy](https://pypi.org/project/scipy/)\n",
    "- [pandas](https://pypi.org/project/pandas/)\n",
    "- [scikit-learn](https://pypi.org/project/scikit-learn/)\n",
    "- [matplolib](https://pypi.org/project/matplotlib/)\n",
    "- [jupyter](https://pypi.org/project/jupyter/)\n",
    "- [ramp-workflow](https://pypi.org/project/ramp-workflow/)\n",
    "- [ramp-utils](https://github.com/paris-saclay-cds/ramp-board/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will install the required pacakge dependencies, if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/maja/anaconda3/lib/python3.7/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.18.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied: ramp-workflow in /home/maja/anaconda3/lib/python3.7/site-packages (0.3.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (0.23.0)\n",
      "Requirement already satisfied: joblib in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (0.13.2)\n",
      "Requirement already satisfied: scipy in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.3.1)\n",
      "Requirement already satisfied: click in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (7.0)\n",
      "Requirement already satisfied: cloudpickle in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.2.2)\n",
      "Requirement already satisfied: numpy in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.18.4)\n",
      "Requirement already satisfied: pandas in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-workflow) (1.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/maja/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.22->ramp-workflow) (2.0.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-workflow) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-workflow) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/maja/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->ramp-workflow) (1.12.0)\n",
      "Collecting ramp-utils\n",
      "  Using cached https://files.pythonhosted.org/packages/ca/5c/a60aebe2f9af73da9797c3666ced5d349101b339b5ca097b362ae0b77ea7/ramp_utils-0.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-utils) (5.1.2)\n",
      "Requirement already satisfied: click in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-utils) (7.0)\n",
      "Requirement already satisfied: pandas in /home/maja/anaconda3/lib/python3.7/site-packages (from ramp-utils) (1.0.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-utils) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-utils) (1.18.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/maja/anaconda3/lib/python3.7/site-packages (from pandas->ramp-utils) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/maja/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas->ramp-utils) (1.12.0)\n",
      "Installing collected packages: ramp-utils\n",
      "Successfully installed ramp-utils-0.6.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install ramp-workflow\n",
    "!{sys.executable} -m pip install ramp-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get this notebook running and test your models locally using `ramp-test` (from ramp-workflow), we recommend that you use the Anaconda or Miniconda Python distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: script to download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## viewing the data files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your `data` folder you should now be able to find the directories with names: `subject_1`, `subject_2` and so on. Inside each of them you will find two files: `t1.nii.gz` and `truth.nii.gz`:\n",
    " - `t1.nii.gz` is a file with a 3D T1 (MRI) brain scan of the patient\n",
    " - `truth.nii.gz` is a file with the binary mask of the same size as T1 image. 0 corresponds to no lesion, 1 corresponds to the lesion. The true lesions where traced by the experts by hand\n",
    "\n",
    "If you wish to view any of those files from outside of Python, there are many applications available online. For example you might want to use [ITK-snap](http://www.itksnap.org/pmwiki/pmwiki.php). There, you can load the `t1.nii.gz` as a Main Image and `truth.nii.gz` as a Segmentation to overlap the two. Here, we won't go into the details of using ITK-snap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the images to Python, we will be using [Nilearn](https://nilearn.github.io/) Python library, but there are many other possiblities so feel free to choose your favorite one (if, for your submission, you will want to use a libarary which is not included within the `environment.yml` feel free to contact us and, if reasonable, we will add it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: load the first subject, plot the brain image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: explain the preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: plot few other brain images and the template image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: plot the same images with the mask overlaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todo: why do we not see the mask on some?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TODO: suggest using itk-snap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: (hidden) script for making a movie + show the movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read the masks + show the difference in the mask sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample example script: average the brains or use template to subtracted and see if we get the lesion"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "score: dice, something else? Intersetion over Union? check other in the past papers, explain what is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. scikit image image segmentation example??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deep learning possible ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here we adapted the unet algorithm, explain unet, references etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model with fit (in the starting kit example, we load some pretrained weights to be able to show results here, but note this is not possible for an actual submission):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    predict few of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "show the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Explain how to make the submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain potential possiblity to use AWS services/ limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission <a class=\"anchor\" id=\"Submission\"></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you found a good model you wish to test you should place it in a directory, naming it as you wish, and place it in the `submissions/` folder (you can already find there two submissions in the folders `submissions/starting_kit` and `submissions/lasso_lars` which we talked about above). The file placed in your submission directory (e.g., `starting_kit/` should be called `estimator.py` and should define a function called `get_estimator` that returns a scikit-learn type of pipeline.\n",
    "\n",
    "You can then test your submission locally using the command:\n",
    "\n",
    "`ramp-test --submission <your submission folder name>`\n",
    "\n",
    "if you prefer to run a quick test on much smaller subset of data you can add `--quick-test` option:\n",
    "\n",
    "`ramp-test --submission <your submission folder name> --quick-test`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on how to submit your code on [ramp.studio](https://ramp.studio/), refer to the [online documentation](https://paris-saclay-cds.github.io/ramp-docs/ramp-workflow/stable/using_kits.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
